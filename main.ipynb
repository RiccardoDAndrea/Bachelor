{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeitserie erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_eries(batch_size, n_steps):\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  # Welle 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20)) # Welle 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)   # Rauschen\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_eries(10000, n_steps + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.Sequential([\n",
    "#     keras.layers.Flatten(input=(50, 1)),\n",
    "#     keras.layers.Dense(1)\n",
    "# ])\n",
    "\n",
    "# model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "# model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Das einfachste RNN das man bauen könnte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(1, input_shape=[None, 1])\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mehrere Zeitschritte vorhersagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = generate_time_eries(1, n_steps + 10)\n",
    "X_new, Y_new = series[:, :n_steps], series[:, n_steps:]\n",
    "X = X_new\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "\n",
    "y_pred = X[:, n_steps:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorhersage des DAX Kurses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/raw/^GDAXI.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.describe())\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_data = len(data)     # rows that data has\n",
    "split_ratio = 0.7           # %70 train + %30 validation\n",
    "length_train = round(length_data * split_ratio)  \n",
    "length_validation = length_data - length_train\n",
    "print(\"Data length :\", length_data)\n",
    "print(\"Train data length :\", length_train)\n",
    "print(\"Validation data lenth :\", length_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:length_train].iloc[:,:2] \n",
    "train_data['Date'] = pd.to_datetime(train_data['Date'])  # converting to date time object\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = data[length_train:].iloc[:,:2]\n",
    "validation_data['Date'] = pd.to_datetime(validation_data['Date'])  # converting to date time object\n",
    "validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = train_data.Open.values\n",
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change 1d array to 2d array\n",
    "# Changing shape from (1692,) to (1692,1)\n",
    "dataset_train = np.reshape(dataset_train, (-1,1))\n",
    "dataset_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "\n",
    "# scaling dataset\n",
    "dataset_train_scaled = scaler.fit_transform(dataset_train)\n",
    "\n",
    "dataset_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,6))\n",
    "plt.plot(dataset_train_scaled)\n",
    "plt.xlabel(\"Days as 1st, 2nd, 3rd..\")\n",
    "plt.ylabel(\"Open Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "time_step = 50\n",
    "\n",
    "for i in range(time_step, length_train):\n",
    "    X_train.append(dataset_train_scaled[i-time_step:i,0])\n",
    "    y_train.append(dataset_train_scaled[i,0])\n",
    "    \n",
    "# convert list to array\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train before reshape :\",X_train.shape)\n",
    "print(\"Shape of y_train before reshape :\",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "y_train = np.reshape(y_train, (y_train.shape[0],1))\n",
    "\n",
    "print(\"Shape of X_train after reshape :\",X_train.shape)\n",
    "print(\"Shape of y_train after reshape :\",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Dropout, Input\n",
    "\n",
    "# initializing the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# defining the input shape\n",
    "regressor.add(Input(shape=(X_train.shape[1], 1)))\n",
    "\n",
    "# adding first RNN layer and dropout regularization\n",
    "regressor.add(SimpleRNN(units=50, activation=\"tanh\", return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# adding second RNN layer and dropout regularization\n",
    "regressor.add(SimpleRNN(units=50, activation=\"tanh\", return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# adding third RNN layer and dropout regularization\n",
    "regressor.add(SimpleRNN(units=50, activation=\"tanh\", return_sequences=True))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# adding fourth RNN layer and dropout regularization\n",
    "regressor.add(SimpleRNN(units=50))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "# adding the output layer\n",
    "regressor.add(Dense(units=1))\n",
    "\n",
    "# compiling RNN\n",
    "regressor.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"accuracy\"])\n",
    "\n",
    "# fitting the RNN\n",
    "history = regressor.fit(X_train, y_train, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Loss vs Epochs\n",
    "plt.figure(figsize =(10,7))\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.title(\"Simple RNN model, Loss vs Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Accuracy vs Epochs\n",
    "plt.figure(figsize =(10,5))\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracies\")\n",
    "plt.title(\"Simple RNN model, Accuracy vs Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_train)  # predictions\n",
    "y_pred = scaler.inverse_transform(y_pred) # scaling back from 0-1 to original\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = scaler.inverse_transform(y_train) # scaling back from 0-1 to original\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.plot(y_pred, color = \"b\", label = \"y_pred\" )\n",
    "plt.plot(y_train, color = \"g\", label = \"y_train\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Open price\")\n",
    "plt.title(\"Simple RNN model, Predictions with input X_train vs y_train\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_validation = validation_data.Open.values  # getting \"open\" column and converting to array\n",
    "dataset_validation = np.reshape(dataset_validation, (-1,1))  # converting 1D to 2D array\n",
    "scaled_dataset_validation =  scaler.fit_transform(dataset_validation)  # scaling open values to between 0 and 1\n",
    "print(\"Shape of scaled validation dataset :\",scaled_dataset_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X_test and y_test\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(time_step, length_validation):\n",
    "    X_test.append(scaled_dataset_validation[i-time_step:i,0])\n",
    "    y_test.append(scaled_dataset_validation[i,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to array\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_test before reshape :\",X_test.shape)\n",
    "print(\"Shape of y_test before reshape :\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.reshape(X_test, (X_test.shape[0],X_test.shape[1],1))  # reshape to 3D array\n",
    "y_test = np.reshape(y_test, (-1,1))  # reshape to 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_test after reshape :\",X_test.shape)\n",
    "print(\"Shape of y_test after reshape :\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions with X_test data\n",
    "y_pred_of_test = regressor.predict(X_test)\n",
    "# scaling back from 0-1 to original\n",
    "y_pred_of_test = scaler.inverse_transform(y_pred_of_test) \n",
    "print(\"Shape of y_pred_of_test :\",y_pred_of_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation\n",
    "plt.figure(figsize = (30,10))\n",
    "plt.plot(y_pred_of_test, label = \"y_pred_of_test\", c = \"orange\")\n",
    "plt.plot(scaler.inverse_transform(y_test), label = \"y_test\", c = \"g\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Open price\")\n",
    "plt.title(\"Simple RNN model, Prediction with input X_test vs y_test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation\n",
    "plt.subplots(figsize =(30,12))\n",
    "plt.plot(train_data.Date, train_data.Open, label = \"train_data\", color = \"b\")\n",
    "plt.plot(validation_data.Date, validation_data.Open, label = \"validation_data\", color = \"g\")\n",
    "plt.plot(train_data.Date.iloc[time_step:], y_pred, label = \"y_pred\", color = \"r\")\n",
    "plt.plot(validation_data.Date.iloc[time_step:], y_pred_of_test, label = \"y_pred_of_test\", color = \"orange\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Open price\")\n",
    "plt.title(\"Simple RNN model, Train-Validation-Prediction\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = scaler.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(\n",
    "    LSTM(64,return_sequences=True,input_shape = (X_train.shape[1],1))) #64 lstm neuron block\n",
    "model_lstm.add(\n",
    "    LSTM(64, return_sequences= False))\n",
    "model_lstm.add(Dense(32))\n",
    "model_lstm.add(Dense(1))\n",
    "model_lstm.compile(loss = \"mean_squared_error\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "history2 = model_lstm.fit(X_train, y_train, epochs = 10, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(10,5))\n",
    "plt.plot(history2.history[\"loss\"])\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Losses\")\n",
    "plt.title(\"LSTM model, Accuracy vs Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize =(30,12))\n",
    "plt.plot(scaler.inverse_transform(model_lstm.predict(X_test)), label = \"y_pred_of_test\", c = \"orange\" )\n",
    "plt.plot(scaler.inverse_transform(y_test), label = \"y_test\", color = \"g\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Open price\")\n",
    "plt.title(\"LSTM model, Predictions with input X_test vs y_test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_input = data.iloc[-time_step:].Open.values               # getting last 50 rows and converting to array\n",
    "X_input = scaler.fit_transform(X_input.reshape(-1,1))      # converting to 2D array and scaling\n",
    "X_input = np.reshape(X_input, (1,50,1))                    # reshaping : converting to 3D array\n",
    "print(\"Shape of X_input :\", X_input.shape)\n",
    "X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_RNN_prediction = scaler.inverse_transform(regressor.predict(X_input))\n",
    "LSTM_prediction = scaler.inverse_transform(model_lstm.predict(X_input))\n",
    "print(\"Simple RNN, Open price prediction for 3/18/2017      :\", simple_RNN_prediction[0,0])\n",
    "print(\"LSTM prediction, Open price prediction for 3/18/2017 :\", LSTM_prediction[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/raw/^GDAXI.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))\n",
    "X_var = data[[\"Open\",\"Close\"]]\n",
    "train_slider = 60\n",
    "validation_slider = 20\n",
    "n_steps= 50\n",
    "\n",
    "X_train, y_train = data[[\"Open\",\"Close\"]][:int(len(data)*train_slider/100)], data[\"Date\"][:int(len(data)*train_slider/100)]\n",
    "X_val, y_val = data[[\"Open\",\"Close\"]][:int(len(data)*validation_slider/100)], data[\"Date\"][:int(len(data)*validation_slider/100)]\n",
    "print(data.shape,X_train.shape, y_train.shape)\n",
    "print(data.shape,X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.to_datetime(y_train)\n",
    "y_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = X_train.Open\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset_train = np.reshape(dataset_train, (-1,1))\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "\n",
    "\n",
    "# scaling dataset\n",
    "dataset_train_scaled = scaler.fit_transform(dataset_train)\n",
    "\n",
    "dataset_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize = (15,6))\n",
    "plt.plot(dataset_train_scaled)\n",
    "plt.xlabel(\"Days as 1st, 2nd, 3rd..\")\n",
    "plt.ylabel(\"Open Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/raw/^GDAXI.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))\n",
    "X_var = data[[\"Open\",\"Close\"]]\n",
    "train_slider = 60\n",
    "validation_slider = 20\n",
    "n_steps= 50\n",
    "\n",
    "X_train, y_train = data[[\"Open\",\"Close\"]][:int(len(data)*train_slider/100), :n_steps], data[\"Date\"][:int(len(data)*train_slider/100), -1]\n",
    "X_val, y_val = data[[\"Open\",\"Close\"]][:int(len(data)*validation_slider/100)], data[\"Date\"][:int(len(data)*validation_slider/100)]\n",
    "print(data.shape,X_train.shape, y_train.shape)\n",
    "print(data.shape,X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://github.com/bnsreenu/python_for_microscopists/blob/master/166a-Intro_to_time_series_Forecasting_using_LSTM.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Flatten\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"data/raw/^GDAXI.csv\", usecols=[1])\n",
    "dataframe = dataframe.dropna()\n",
    "#plt.plot(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9213, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert pandas dataframe to numpy array\n",
    "dataset = dataframe.values\n",
    "dataset = dataset.astype('float32')\n",
    "dataset.shape\n",
    "# Datentypen ändern von int64 zu float32\n",
    "# sobald die values sind die bereits float 64 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9213, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSTM uses sigmoid and tanh that are sensitive to magnitude so values need to be normalized\n",
    "# normalize the dataset\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) #Also try QuantileTransformer\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "dataset.shape\n",
    "\n",
    "# Daten umarrangerien damit sie eine Saklierung haben von 0 bis 1. Wobei 1 = max und 0 = min\n",
    "#scaler.fit = transformiert erst die daten die zeile davor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.66)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "\n",
    "# daten aufteilen in train und test\n",
    "# validation data kommt er später"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sequences(dataset, seq_size=1):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(dataset)-seq_size-1):\n",
    "        #print(i)\n",
    "        window = dataset[i:(i+seq_size), 0]\n",
    "        x.append(window)\n",
    "        y.append(dataset[i+seq_size, 0])\n",
    "        \n",
    "    return np.array(x),np.array(y)\n",
    "\n",
    "\n",
    "# Dieser Prozess hilft dem RNN-Modell, zeitliche Abhängigkeiten \n",
    "# und Muster im Datensatz zu lernen, indem es auf frühere Werte in \n",
    "# den Sequenzen zurückgreift, um zukünftige Werte vorherzusagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set: (6074, 5)\n",
      "Shape of test set: (3127, 5)\n"
     ]
    }
   ],
   "source": [
    "seq_size = 5  # Number of time steps to look back \n",
    "#Larger sequences (look further back) may improve forecasting.\n",
    "\n",
    "trainX, trainY = to_sequences(train, seq_size)\n",
    "testX, testY = to_sequences(test, seq_size)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Shape of training set: {}\".format(trainX.shape))\n",
    "print(\"Shape of test set: {}\".format(testX.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape#[0]\n",
    "#trainX.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Single LSTM with hidden Dense...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(None, seq_size)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "#                        verbose=1, mode='auto', restore_best_weights=True)\n",
    "model.summary()\n",
    "print('Train...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, trainY, validation_data=(testX, testY), verbose=2, epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict[:,0].shape, trainPredict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "#we must shift the predictions so that they align on the x-axis with the original dataset. \n",
    "trainPredictPlot = np.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[seq_size:len(trainPredict)+seq_size, :] = trainPredict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataset)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(seq_size*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Beispiel-Daten\n",
    "data = {'Date': ['2022-06-18 10:30:00', '2022-06-19 11:45:00', '2022-06-20 12:00:00']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sicherstellen, dass die 'Date'-Spalte im DateTime-Format ist\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# # Extrahieren Sie das Datum ohne die Zeitkomponente\n",
    "# df['Date'] = df['Date'].dt.date\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2,offsets1, offsets2 = np.random.rand(4,batch_size, 1)\n",
    "    time = np.linspace(0,1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))    # Welle 1\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))   # Welle 2\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)     # + Rauschen\n",
    "    return series[..., np.newaxis].astype(np.float32)\n",
    "n_steps = 50\n",
    "\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "series.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
